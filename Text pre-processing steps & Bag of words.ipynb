{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f36cad",
   "metadata": {},
   "source": [
    "# Working with Text Data -> Bag Of Words"
    "##Pre-Processing steps and  Convert Text to Numerical Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35538d",
   "metadata": {},
   "source": [
    "### Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b153d09e",
   "metadata": {},
   "source": [
    "\n",
    "Text Analysis is a major application field for machine learning algorithms. Some of the major application areas of NLP are:\n",
    "\n",
    "    1. Spell Checker, Keyword Search etc,\n",
    "    2. Sentiment Analysis, Spam Classification\n",
    "    3. Machine Translation\n",
    "    4. Chatbots/Dialog Systems\n",
    "    5. Question Answering Systems etc..,\n",
    "    \n",
    "However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86819c7",
   "metadata": {},
   "source": [
    "### Why NLP is hard?\n",
    "\n",
    "  1. Complexity of representation\n",
    "  2. Ambiguity in Natural Language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31944b2f",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "  1. Tokenisation\n",
    "  2. Removing special characters\n",
    "  3. Convert sentence into lower case\n",
    "  4. Removing stop words\n",
    "  5. Stemming or Lemmatization  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714cd02",
   "metadata": {},
   "source": [
    "### Techniques to convert Text to Numerical Vectors\n",
    "  1. Bag of Words\n",
    "  2. TF IDF (Term Frequency - Inverse Document Frequency)\n",
    "  3. Word2Vec (by Google)\n",
    "  4. GloVe (Global Vectors by Stanford) \n",
    "  5. Pretrained GloVe Embeddings\n",
    "  6. FastText (by Facebook) \n",
    "  7. ELMo (Embeddings from Language Models) \n",
    "  8. BERT (Bidirectional Encoder Representations from Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47956b",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f733eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92297a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of 23times.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE %age of foolishness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text\n",
       "0      it Was the best oF Times $\n",
       "1    It was The worst of 23times.\n",
       "2      IT 9 was tHe age Of wisdom\n",
       "3  it was thE %age of foolishness"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_text = ['it Was the best oF Times $', \n",
    "            'It was The worst of 23times.',\n",
    "            'IT 9 was tHe age Of wisdom', \n",
    "            'it was thE %age of foolishness']\n",
    "\n",
    "df = pd.DataFrame({'text': lst_text})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7c0007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jessy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jessy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Jessy\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Downloading wordnet before applying Lemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e442fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5bf9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialise the inbuilt Stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f69cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also use Lemmatizer instead of Stemmer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100de5f9",
   "metadata": {},
   "source": [
    "### Text Preprocessing Steps\n",
    "\n",
    "Text Preprocessing steps include some essential tasks to clean and remove the noise from the available data.\n",
    "\n",
    "  1. ***Removing Special Characters and Punctuation***\n",
    "  \n",
    "\n",
    "  2. ***Converting to Lower Case -*** We convert the whole text corpus to lower case to reduce the size of the vocabulary of our text data.\n",
    "  \n",
    "\n",
    "  3. ***Removing Stop Words -*** Stopwords don't contribute to the meaning of a sentence. So, we can safely remove them without changing the meaning of the sentence. For eg: it, was, any, then, a, is, by, etc are the stopwords.\n",
    "  \n",
    "\n",
    "  4. ***Stemming or Lemmatization -*** Stemming is the process of getting the root form of a word. For eg: warm, warmer, warming can be converted to warm.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d18554c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This 1is Natural-LAnguage-Processing.& This is @Text pre-Processing4\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"This 1is Natural-LAnguage-Processing.& This is @Text pre-Processing4\"\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4df571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This  is Natural LAnguage Processing   This is  Text pre Processing \n"
     ]
    }
   ],
   "source": [
    "# Removing special characters and digits\n",
    "sentence = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8956caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this  is natural language processing   this is  text pre processing \n"
     ]
    }
   ],
   "source": [
    "# change sentence to lower case\n",
    "sentence = sentence.lower()\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9e580d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'natural', 'language', 'processing', 'this', 'is', 'text', 'pre', 'processing']\n"
     ]
    }
   ],
   "source": [
    "# tokenize into words\n",
    "tokens = sentence.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6765ff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'text', 'pre', 'processing']\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words\n",
    "clean_tokens = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c53fd304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'text', 'pre', 'process']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "clean_tokens_stem = [stemmer.stem(word) for word in clean_tokens]\n",
    "print(clean_tokens_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac887df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural', 'language', 'processing', 'text', 'pre', 'processing']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "clean_tokens_lem = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "print(clean_tokens_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bcf08",
   "metadata": {},
   "source": [
    "## Lets put it all together in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c9df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_text, flag):\n",
    "    # Removing special characters and digits\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "    \n",
    "    # change sentence to lower case\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # remove stop words                \n",
    "    clean_tokens = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Stemming/Lemmatization\n",
    "    if(flag == 'stem'):\n",
    "        clean_tokens = [stemmer.stem(word) for word in clean_tokens]\n",
    "    else:\n",
    "        clean_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    \n",
    "    return pd.Series([\" \".join(clean_tokens), len(clean_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "330be829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age foolish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  1\n",
       "0    best time  2\n",
       "1   worst time  2\n",
       "2   age wisdom  2\n",
       "3  age foolish  2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df['text'].apply(lambda x : preprocess(x, 'stem'))\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b56b8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>text_length_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age foolish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_text_stem  text_length_stem\n",
       "0       best time                 2\n",
       "1      worst time                 2\n",
       "2      age wisdom                 2\n",
       "3     age foolish                 2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns = ['clean_text_stem', 'text_length_stem']\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93e9c99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>text_length_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of 23times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE %age of foolishness</td>\n",
       "      <td>age foolish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text clean_text_stem  text_length_stem\n",
       "0      it Was the best oF Times $       best time                 2\n",
       "1    It was The worst of 23times.      worst time                 2\n",
       "2      IT 9 was tHe age Of wisdom      age wisdom                 2\n",
       "3  it was thE %age of foolishness     age foolish                 2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90acf9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age foolishness</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0  1\n",
       "0        best time  2\n",
       "1       worst time  2\n",
       "2       age wisdom  2\n",
       "3  age foolishness  2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df['text'].apply(lambda x: preprocess(x, 'lemma'))\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c376703a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age foolishness</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_text_lemma  text_length_lemma\n",
       "0        best time                  2\n",
       "1       worst time                  2\n",
       "2       age wisdom                  2\n",
       "3  age foolishness                  2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns = ['clean_text_lemma', 'text_length_lemma']\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cded5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>text_length_stem</th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of 23times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE %age of foolishness</td>\n",
       "      <td>age foolish</td>\n",
       "      <td>2</td>\n",
       "      <td>age foolishness</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text clean_text_stem  text_length_stem  \\\n",
       "0      it Was the best oF Times $       best time                 2   \n",
       "1    It was The worst of 23times.      worst time                 2   \n",
       "2      IT 9 was tHe age Of wisdom      age wisdom                 2   \n",
       "3  it was thE %age of foolishness     age foolish                 2   \n",
       "\n",
       "  clean_text_lemma  text_length_lemma  \n",
       "0        best time                  2  \n",
       "1       worst time                  2  \n",
       "2       age wisdom                  2  \n",
       "3  age foolishness                  2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fff36",
   "metadata": {},
   "source": [
    "# Bag of Word Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ce49d",
   "metadata": {},
   "source": [
    "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This\n",
    "\n",
    "specific strategy (tokenization, counting and normalization) is called the Bag of Words or \"Bag of n-grams\" representation.\n",
    "\n",
    "Documents are described by word occurrences while completely ignoring the relative position information of the words in the \n",
    "\n",
    "document.\n",
    "\n",
    "\n",
    "We will use `CountVectorizer` to convert ***text into a matrix of token count.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10612fe",
   "metadata": {},
   "source": [
    "`Bag of Words`: https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
    "\n",
    "`Code Example`: https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afd66d",
   "metadata": {},
   "source": [
    "***We are going to perform below mentioned steps to understand the entire process:***\n",
    "\n",
    " 1. Converting text to numerical vectors with the help of `CountVectorizer`\n",
    " \n",
    " 2. Understand `fit` and `transform`\n",
    " \n",
    " 3. Looking at `vocabulary_`\n",
    " \n",
    " 4. Converting `sparse matrix` to dense matrix using `toarray()`\n",
    " \n",
    " 5. Understanding `n_gram`\n",
    " \n",
    " \n",
    " \n",
    "### Advantages\n",
    "\n",
    " 1. It is simple to understand and implement like OneHotEncoding.\n",
    " \n",
    " \n",
    " 2. We have a fixed length encoding for any sequence of arbitrary length.\n",
    " \n",
    " \n",
    " 3. Documents with same words/vocabulary will have similar representation. So if two documents have a similar vocabulary,           they’ll be closer to each other in the vector space and vice versa.\n",
    " \n",
    " \n",
    "### Disadvantages\n",
    "\n",
    "1. The size of vector increases with the size of the vocabulary. Thus, sparsity continues to be a problem. One way to control it    is by limiting the vocabulary to n number of the most frequent words.\n",
    "\n",
    "\n",
    "2. It does not capture the similarity between different words that mean the same thing.i.e.`Semantic Meaning` is not                  captured.\n",
    "\n",
    "   > a. \"walk\", \"walked\", and \"walking\". BoW vectors of all three tokens will be equally apart.\n",
    "    \n",
    "   > b. \"search\" and \"explore\" are synonyms. BoW won't capture the semantic similarity of these words.\n",
    "\n",
    "\n",
    "3. This representation does not have any way to handle `out of vocabulary (OOV)`words (i.e., new words that were not seen in the     corpus that was used to build the vectorizer).\n",
    "\n",
    "\n",
    "4. As the name indicates, it is a “bag” of words. Word order information is lost in this representation. One way to control it \n",
    "   is by using `n-grams`.\n",
    "   \n",
    "   \n",
    "5. It suffers from ***curse of high dimensionality.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc3e2a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>text_length_stem</th>\n",
       "      <th>clean_text_lemma</th>\n",
       "      <th>text_length_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "      <td>best time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of 23times.</td>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "      <td>worst time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "      <td>age wisdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE %age of foolishness</td>\n",
       "      <td>age foolish</td>\n",
       "      <td>2</td>\n",
       "      <td>age foolishness</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text clean_text_stem  text_length_stem  \\\n",
       "0      it Was the best oF Times $       best time                 2   \n",
       "1    It was The worst of 23times.      worst time                 2   \n",
       "2      IT 9 was tHe age Of wisdom      age wisdom                 2   \n",
       "3  it was thE %age of foolishness     age foolish                 2   \n",
       "\n",
       "  clean_text_lemma  text_length_lemma  \n",
       "0        best time                  2  \n",
       "1       worst time                  2  \n",
       "2       age wisdom                  2  \n",
       "3  age foolishness                  2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "445f4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vocab = CountVectorizer()\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "\n",
    "dtm = vocab.fit_transform(df['clean_text_lemma'])\n",
    "\n",
    "# fit_transform() could be done seperatly as mentioned below\n",
    "# vocab.fit(df.clean_text_stem)\n",
    "# dtm = vocab.transform(df.clean_text_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0cac264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best': 1, 'time': 3, 'worst': 5, 'age': 0, 'wisdom': 4, 'foolishness': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can look at unique words by using 'vocabulary_'\n",
    "\n",
    "vocab.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63036919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Observe that the type of dtm is sparse\n",
    "\n",
    "print(type(dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "967fd189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6)\n"
     ]
    }
   ],
   "source": [
    "# Lets now print the  shape of this dtm\n",
    "\n",
    "print(dtm.shape)\n",
    "\n",
    "# o/p -> (4, 6)\n",
    "# i.e -> 4 documents and 6 unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e984c6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the dtm\n",
    "\n",
    "print(dtm)\n",
    "\n",
    "# Remember that dtm is a sparse matrix. i.e. zeros wont be stored\n",
    "# Lets understand First line of output -> (0,1)    1\n",
    "# Here (0, 1) means 0th document and 1st(index starting from 0) unique word. \n",
    "# (we have total 4 documents) & (we have total 6 unique words)\n",
    "# (0, 1)    1 -> 1 here refers to the number of occurence of 1st word\n",
    "# Now lets read it all in english.\n",
    "# (0, 1)    1 -> 'times' occurs 1 time in 0th document. \n",
    "# Try to observe -> (3, 2)   1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c8a7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0]\n",
      " [0 0 0 1 0 1]\n",
      " [1 0 0 0 1 0]\n",
      " [1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Since the dtm is sparse, lets convert it into numpy array.\n",
    "\n",
    "print(dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d0e9efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'best', 'foolishness', 'time', 'wisdom', 'worst']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vocab.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0a85ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>time</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  best  foolishness  time  wisdom  worst\n",
       "0    0     1            0     1       0      0\n",
       "1    0     0            0     1       0      1\n",
       "2    1     0            0     0       1      0\n",
       "3    1     0            1     0       0      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm.toarray(), columns=sorted(vocab.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd21723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-grams\n",
    "\n",
    "vocab = CountVectorizer(ngram_range=[1,2])\n",
    "\n",
    "dtm = vocab.fit_transform(df.clean_text_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9af12ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best': 3, 'time': 6, 'best time': 4, 'worst': 8, 'worst time': 9, 'age': 0, 'wisdom': 7, 'age wisdom': 2, 'foolish': 5, 'age foolish': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7bf3e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 1]\n",
      " [1 0 1 0 0 0 0 1 0 0]\n",
      " [1 1 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# convert sparse matrix to numpy array\n",
    "print(dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c011285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age foolish</th>\n",
       "      <th>age wisdom</th>\n",
       "      <th>best</th>\n",
       "      <th>best time</th>\n",
       "      <th>foolish</th>\n",
       "      <th>time</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "      <th>worst time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  age foolish  age wisdom  best  best time  foolish  time  wisdom  \\\n",
       "0    0            0           0     1          1        0     1       0   \n",
       "1    0            0           0     0          0        0     1       0   \n",
       "2    1            0           1     0          0        0     0       1   \n",
       "3    1            1           0     0          0        1     0       0   \n",
       "\n",
       "   worst  worst time  \n",
       "0      0           0  \n",
       "1      1           1  \n",
       "2      0           0  \n",
       "3      0           0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtm.toarray(), columns=sorted(vocab.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b55a91",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "1. `vect.fit(lst_text)` **learns the vocabulary**\n",
    "2. `vect.transform(lst_text)` **uses the fitted vocabulary to build a document-term matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480ba36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
